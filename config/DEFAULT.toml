# Default experimental settings, required to reproduce https://github.com/jayelm/emergent-generalization

name = "DEFAULT" # experiment name - should be the same as file name
experiments_directory = "../exp"
cuda = true
wandb = false
wandb_project_name = "cc"
use_lang = true
copy_receiver = false
receiver_only = false
share_feat_model = false
share_language_model = false
n_transformer_heads = 8
n_transformer_layers = 5
joint_training = false
joint_training_lambda = 1.0
reference_game = false
reference_game_xent = false
no_cross_eval = false
ignore_language = false
ignore_examples = false
debug = false
vis = false
receiver_reset_interval = 0.0
force_reference_game = false # Can be used in zero-shot eval
force_concept_game = false # Can be used in zero-shot eval
force_setref_game = false # Can be used in zero-shot eval
zero_shot_eval_epochs = 5
save_interval = 10

[data]
dataset = "../data/shapeworld"
load_shapeworld_into_memory = false
batch_size = 32
percent_novel = 1.0
n_examples = 10 # number of examples seen by agents, including distractors
ref_dataset="../data/shapeworld_ref"
n_sample = 2E5 # Number of samples for inspecting the language. Used in sample.py
n_workers = 0

[optimiser]
class = "AdamW"
accumulator_steps = 4
lr = 1e-4
weight_decay = 0.0
clip_grad_norm = 100.0
log_interval = 100

[scheduler]
epochs = 100
range_test = false
microcycle_type = "flat"
macrocycle_type = "flat"

[sender]
class = "Sender"
feature_model = "Conv4"
vision_dropout = 0.1
prototyper = "AveragePrototyper"
language_model = "SenderGRULM"

[sender_feature_model]
embedding_size = 16 # Only applies to Transformer vision models
layers = 4 # Only applies to Transformer vision models
heads = 4 # Only applies to Transformer vision models
utility_tokens = 0 # Only applies to Transformer vision models

[sender_language_model]
token_embedding_size = 500
d_model = 1024
vocabulary = 11
message_length = 4
softmax_temperature = 1.0
confidence_based_exploration = true
uniform_weight = 0.1
dropout = 0.1
layers = 1
bidirectional = False
heads = 4 # Heads per layer - only applies to Transformer language models
utility_tokens = 4 # Only applies to Transformer language models

[receiver]
class = "Receiver"
feature_model = "Conv4"
comparer = "BilinearGRUComparer"
vision_dropout = 0.1

[receiver_comparer]
token_embedding_size = 500
d_model = 1024
dropout = 0.1
bidirectional = false
layers = 1
message_length = 4 # Only applies to Transformer comparers. Should be the same as sender_language_model.message_length
heads = 4 # Only applies to Transformer comparers
utility_tokens = 0 # Only applies to Transformer comparers

bidirectional = False
dropout = 0.1
temperature = 1.0

[shapeworld.data]
ref_dataset="../data/shapeworld_ref"
n_examples=20 # number of examples given to teacher/student, divided evenly b/t targets and distractors (must be even!)

[shapeworld.optimiser]
accumulator_steps=4

[shapeworld.sender.arguments]
vocabulary = 14
message_length = 7
uniform_weight = 0.1

[shapeworld.receiver.arguments]
vocabulary = 14
message_length = 7

[birds.data]
batch_size = 16
n_workers = 4
ref_dataset = "../data/cub"

[birds.sender.arguments]
vocabulary = 20
message_length = 10
image_encoder = "PretrainedResNet18"
pretrained_feat_model = true

[birds.receiver.arguments]
vocabulary = 20
message_length = 10
image_encoder = "PretrainedResNet18"
pretrained_feat_model = true